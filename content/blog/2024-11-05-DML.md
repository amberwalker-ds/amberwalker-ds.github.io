<!-- title: Double Machine Learning: Analyzing Peace Agreement Effects -->
<!-- date: 2024-11-05 -->
<!-- author: Amber Walker -->
<!-- summary:  Double Machine Learning for Dynamic Panel Data-->
<!-- featured_image: https://raw.githubusercontent.com/amberwalker-ds/amberwalker-ds.github.io/master/assets/images/dml-graph.jpeg -->
 <!-- category: NLP -->
<body>
<figure>
    <img src="https://raw.githubusercontent.com/amberwalker-ds/amberwalker-ds.github.io/master/assets/images/dml-graph.jpeg" alt="Double Machine Learning for Panel Data" width="1000" height="700">
</figure>

<p>
We often hear about peace agreements being signed, especially in countries with a lot of violence, but how much of a difference do they actually make in reducing violence? While leaders sign these treaties with hopes of ending violence, the real-world impact of these agreements can be super challenging to measure. We know that peace isn’t instant—some effects might take months or years to show up, and a ton of factors can influence whether violence actually subsides.
</p>
<p>
During my master’s program, a colleague and I decided to take on this challenge: we wanted to measure the true effect of peace agreements on violence. To do this, we used Double Machine Learning (DML) as it can handle larger and more complex data. Our challenge was adapting DML to work with observational panel data. In this article, I'll walk you through how we overcame challenges all while uncovering the true impact of peace agreements on violence. If you want to take a look at the code, or look at the paper, here is the <a href="https://github.com/amberwalker-ds/DML-for-Panel-Data" target="_blank">GitHub Repository</a>.
</p>
<hr>
<h2>The Challenge of Measuring Cause and Effect</h2>
<p>
Understanding the impact of peace agreements is no easy task. Unlike a controlled lab experiment, where you can control every variable, real-world data is messy and full of complexities. For example, if violence drops after a peace agreement, how do we know for sure that the agreement caused it? There could be other factors, like a country’s economy improving or international aid coming in. This is why understanding cause and effect in social science can be incredibly tricky.
</p>
<hr>
<h2>Enter Double Machine Learning (DML)</h2>
<p>
Traditional causal inference methods often struggle with these complexities, but there’s a new tool on the block that leverages machine learning: Double Machine Learning. This method, inspired by the work of Chernozhukov et al. (2018), combines machine learning’s power to handle large, complex datasets with causal inference to separate correlation from causation. In simple terms, DML helps us better understand what’s really going on by isolating the effect of the peace agreement (the treatment) from everything else.
</p>
<hr>
<h2>Breaking Down the Method</h2>
<p>
To understand DML, let’s first break down the terms:
    <p>
    <ul>
        <li> <b> Treatment:</b> This is the peace agreement itself—whether a peace deal was signed or not.</li>
        <li> <b> Outcome:</b> This is what we’re interested in measuring—the level of violence in a country. </li> 
        <li> <b>Confounders:</b> These are other factors, like economic stability or sentiment in the news, that can influence both the likelihood of a peace agreement being signed and the level of violence. </li> 
    </ul>
    </p>
</p>
<hr>
<h2>How Does DML Work?</h2>
<p>
<ol>
    <li><b>Confounders Control:</b> First, DML uses machine learning to control for these confounders. It helps us isolate the true effect of a peace agreement, keeping other influencing factors in check.</li>
    <li><b>Orthogonalization and Cross-Fitting:</b> These are two key steps that make DML robust. Orthogonalization removes the effect of confounding variables, while cross-fitting helps prevent overfitting by dividing the data and testing on separate folds. It’s like double-checking our results to make sure they’re reliable.</li>
</ol>
</p>
<hr>
<h2>Our Special Take on DML: Handling Panel Data and Fixed Effects</h2>
<p>
So what makes our approach so special? For the study, we designed a tailored Double Machine Learning approach to address the challenges of panel data analysis, including handling fixed effects and accounting for time-lagged impacts of peace agreements.
</p>
<p>
First off, what the heck is panel data? Panel data is a type of data that tracks many different entities (like countries, companies, or individuals) over time. Basically, it includes repeated measurements for each entity across different time periods. For example, panel data could show the economic indicators (like inflation) for several countries over multiple years, helping us study both the differences between countries and their changes over time.
<figure>
    <img src="https://raw.githubusercontent.com/amberwalker-ds/amberwalker-ds.github.io/master/assets/images/panel_data.png" alt="Example Panel Data Generated in Python by Author" width="600" height="400">
    <figcaption>Example Panel Data Generated in Python by Author</figcaption>
</figure>

</p>
<p>
Okay, so here’s what sets our method apart:
    <ol>
        <li><b>Handling Fixed Effects in Panel Data:</b> 
        <div>
        One of the main challenges with panel data is controlling for <b>fixed effects</b>—the unique, unobserved characteristics that vary across countries but remain constant over time. Examples could include cultural factors, historical backgrounds, or long-term political conditions, all which could influence the likelihood of peace agreements and violence levels.
        <div>
        To solve this, we used <b>one-hot encoding</b> for each country, introducing “dummy” variables that represent country-specific fixed effects. This enabled us to account for each country's unique characteristics without directly observing them, reducing bias in our causal estimates.
        </li>
        <li><b>Accounting for Lagged Effects:</b>
        <div>
        Peace agreements often don’t have immediate impacts. Instead, their effects on violence can take time to materialize. To capture this delayed effect, we incorporated lagged variables that represent the treatment variable (peace agreement status) in previous time periods. By doing so, our model could assess both the immediate and longer-term effects of peace agreements on violence, providing a more comprehensive view of how these agreements influence conflict dynamics over time.
        </li>
    </ol>
</p>
<hr>
<h2>The Data: Understanding Peace Agreements and Violence Levels</h2>
<p>
To measure the impact of peace agreements on violence, we curated a dataset from various sources that allowed us to analyze both quantitative and qualitative factors over time. Here’s a breakdown of the different types of data we used:
    <ol>
        <li>
            <b>Peace Agreements Data:</b> 
            <p>We included data from the <b>PA-X Peace Agreement Database</b>, a collection of peace agreements signed between 1990 and 2023. It includes details such as the country of the agreement, the signing date, and unique identifiers for each agreement.
                <figure>
                    <img src="https://raw.githubusercontent.com/amberwalker-ds/amberwalker-ds.github.io/master/assets/images/number_ofpa.webp" alt="Double Machine Learning for Panel Data" width="600" height="400">
                    <figcaption>Plot shows the number of peace agreements signed each year</figcaption>
                </figure>
            </p>
        </li>
        <li><b>Fatalities Data (Violence Intensity):</b>
            <p>To capture violence levels, we used the Uppsala Conflict Data Program (UCDP) Georeferenced Event Dataset (GED). This dataset provides monthly data on violent incidents globally, categorized into:
                <ol>
                    <li><b>Battle-related violence:</b> Armed clashes between organized groups.</li>
                    <li><b>One-sided violence:</b> Incidents where civilians are deliberately targeted and killed.</li>
                    <li><b>Non-state conflict violence:</b> Conflicts between non-state actors like rebel or ethnic groups.</li>
                </ol>
            </p>
        </li>
        <li><b>Text Data:</b>
            <p>Additionally, we utilized the data compiled in the <b>Mueller and Rauh (2022) dataset</b>. The data is comprised of over six million news articles from various sources spanning from 1989 to the present. This text data was already processed using <b>Natural Language Processing (NLP)</b> techniques, specifically <b>Latent Dirichlet Allocation (LDA)</b>, to identify topics within the news articles. To capture how news cycles emphasize recent events, an <b>Exponential Weighted Moving Average (EWMA)</b> method was also applied to give more weight to recent articles, ensuring the topic distributions reflected the latest developments.
                    <img src="https://raw.githubusercontent.com/amberwalker-ds/amberwalker-ds.github.io/master/assets/images/download.png" alt="The above graph shows the news topics shares in Libya, you can see spike in politics after the first peace agreement is signed (it starts to rise even before), but a drop in family & social life, and military & operations after the signing." width="600" height="400">
            </p>
        </li>
        <li><b>Constructing Violence Intensity as the Target Variable:</b>
            <p>Our target variable, violence intensity, was calculated first by normalizing fatalities against the population of each country. We then took the log of this measure to address skewness, resulting in a smoother distribution. This allowed us to compare violence levels before and after peace agreements, revealing any potential impact from these treaties.
                    <img src="https://raw.githubusercontent.com/amberwalker-ds/amberwalker-ds.github.io/master/assets/images/outcome_distribution.png" alt="Log of Violence Intensity" width="600" height="400">
            </p>
        </li>
    </ol>
</p>
<hr>
<h2>Our Method and Implementation</h2>
Okay, now we get to the meat and potatoes of our project, where we implemented Double Machine Learning, specifically adapted for panel data. Here’s a simplified breakdown of the steps we took:
     <ol>
         <li><b>Controlling for Country-Specific Differences:</b>
            <p>As mentioned earlier, we introduced dummy variables for each country, effectively capturing and controlling for the country-specific effects. Basically, we are putting each country on the same playing field.
            </p>
            </li>
         <li><b>Including Lagged Variables for Delayed Effects:</b> 
             <P>We know impact of a peace agreement might not be immediate—it could take months for violence levels to change. To capture this, we included <b>lagged variables</b> (e.g., peace agreement status from previous months) in our model. This allowed us to see both the immediate and delayed effects of peace agreements on violence.
             </p>
             <p> We lagged the treatment variable (whether a peace agreement was in place or not) back by 12 periods, and did this for the covariates as well (the other factors influencing both peace agreements and violence). Wait, that means we had to run the DML model for each lagged treatment variable? Yep, we ran it for each of the 12 lagged variables.
             </p>
         </li>
         <li><b>Splitting the Data for Reliable Results (Cross-Fitting):</b>
            <p>To avoid overfitting—where a model performs well on training data but poorly on new data—we used a technique called cross-fitting. This is a crucial step of DML. This involved splitting our data into different groups, or “folds.” We trained our model on some folds and validated it on others, making sure the model didn’t use the same data for both steps.
            </p>
            <p>But, how did we split the data into different folds while respecting the temporal order of the data? That's where we utilized a package called PanelSplit that effectively splits the data while maintaining the temporal and cross-sectional dependencies inherent in panel data. This is a super useful package for anyone dealing with panel data! Here is the <a href="https://github.com/4Freye/panelsplit" target="_blank">GitHub Repository</a>
            </p>
         </li> 
         <li><b>Estimating the True Causal Effect of Peace Agreements on Violence:</b> 
            <p>In DML, we estimate certain “nuisance parameters” to control for factors that influence both the treatment (peace agreements) and the outcome (violence). Here's a breakdown:
             <ul>
                 <li>Step 1 - Treatment Model: We used a Random Forest Classifier to estimate the likelihood of a peace agreement being in place, considering other influencing variables.</li>
                 <li>Step 2 - Outcome Model: Then we used a Random Forest Regressor to estimate the intensity of violence, again accounting for various factors.</li>
                 <li>Step 3 - Regress the Residuals:
                     <ul>
                         <li>First, we calculate the residuals. What are residuals? This is basically how far off your predictions are from the true values. So to find that, we subtract the predictions from the actual values.</li>
                         <li>Second, we regress the outcome residuals on the treatment residuals to estimate the causal effect (basically we just run a regression analysis to find the relationship between the variables). This part is called <b>Orthogonalization</b>.</li>
                     </ul>
                 </li>
             </ul>
             </p>
         </li>
              <li><b>Averaging Results for Reliable Causal Estimates:</b>
                <p>Finally, we averaged the results across all folds to get a good, stable estimate of the impact of peace agreements on violence. This process involved running the model multiple times and averaging the results, making sure that our findings weren’t overly influenced by any one part of the data (Yes, this code took hours to run).
                </p>
         </li>
     </ol>

<h3>Key Techniques: Orthogonalization and Cross-Fitting</h3>
<p>
Two essential techniques in DML—orthogonalization and cross-fitting—helped improve the reliability of our results:
    <ul>
        <li><b>Orthogonalization</b> reduces biases from confounding variables. Remember this was the part where we regressed the residuals.</li>
        <li><b>Cross-fitting</b> divides data to ensure that training and validation are done on separate portions.</li>
    </ul>
</p>
<hr>
<h2>Results and Final Thoughts</h2>
<p>
The results show that peace agreements lead to a significant reduction in violence. In order to test this and make sure our results are reliable, we ran a sensitivity analysis test with 'placebo' lagged variables. What that means is that we lagged the treatment variable <b>forward</b>, meaning we were looking at the causal effect of 'fake' peace agreements. The results were all not statistically significant, so this is good news!
</p>

<h3>1. Impact of Peace Agreements on Violence Intensity</h3>

<p>To really understand the effects of peace agreements, we looked at each of the coefficients generated by each run:</p>

<ul>
    <li><b>Negative Coefficients Across Lags</b>: All lags, including treatment not lagged, produced negative coefficients, indicating a consistent trend.</li>
    <li><b>Statistical Significance</b>: The confidence intervals for the DML results, <b>except</b> for treatment with no lag and treatment lagged by 12 periods, did not include zero. This suggests robust results and a clear negative effect of peace agreements on violence over time.</li>
</ul>
                <figure>
                    <img src="https://raw.githubusercontent.com/amberwalker-ds/amberwalker-ds.github.io/master/assets/images/lag_effects.jpeg" alt="Double Machine Learning for Panel Data" width="900" height="600">
                    <figcaption>Here, you can see the estimated treatment effect for each lag. It's clear that all, except 0 and 12, are below the zero line, meaning they are statistically significant.</figcaption>
                </figure>

<h3>2. Robustness Check: Placebo Test</h3>

<p>To confirm that our observed effects weren’t random or driven by unrelated factors, we ran a placebo test (a handy little trick). This involved shifting the “peace agreement” variable backward in time to create “fake” treatments and checking if these placebo treatments produced significant results:</p>

<ul>
    <li><b>Results</b>: Placebo lags showed no significant effects on violence, as their confidence intervals all included zero. This tells us that the observed reduction in violence is most likely due to actual peace agreements rather than random correlations.</li>
</ul>
                <figure>
                    <img src="https://raw.githubusercontent.com/amberwalker-ds/amberwalker-ds.github.io/master/assets/images/plot.jpeg" alt="Double Machine Learning for Panel Data" width="900" height="600">
                    <figcaption>On the left are the estimated treatment effects for the placebo treatments, and on the right are the original estimated treatment effects. You can clearly see violence decrease after the peace agreement is signed.</figcaption>
                </figure>

<h3>3. Exploring Anticipatory and Delayed Effects</h3>

<p>Our findings suggest that peace agreements don’t instantly reduce violence; rather, their effects unfold over time, which makes sense given that peace can take time to manifest. This is something we would like to explore further by building a "phased" treatment—a treatment period that includes multiple periods. This way, we can view treatment as an extended period of time rather than just a single point in a time.</p>
<hr>
<h2>Conclusion</h2>

<p>We were able to demonstrate several key insights:</p>

<ul>
    <li><b>Panel Data</b> can be tackled with DML as long as you carefully split the data and handle fixed effects, such as using one-hot encoding.</li>
    <li>After controlling for all confounders, we showed that peace agreements lead to a <b>significant negative reduction</b> in violence.</li>
    <li>Thanks to the inclusion of lags, we observed that the effect of a peace agreement unfolds gradually over time, and further research is required to investigate a "phased" treatment model.</li>
</ul>
<hr>
<button onclick="topFunction()" id="topBtn" title="Go to top">Top</button>
<script>
// Show the button when the user scrolls down 20px from the top of the document
window.onscroll = function() {scrollFunction()};

function scrollFunction() {
    const topBtn = document.getElementById("topBtn");
    if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
        topBtn.style.display = "block";
    } else {
        topBtn.style.display = "none";
    }
}

// Scroll to the top when the button is clicked
function topFunction() {
    window.scrollTo({ top: 0, behavior: 'smooth' });
}
</script>
<h2>References</h2>
<ol>
    <li>
        Athey, S. and Wager, S. (2021). <i>Policy learning with observational data</i>. 
        <a href="https://onlinelibrary.wiley.com/doi/abs/10.3982/ECTA15732" target="_blank">Econometrica, 89(1):133–161</a>.
    </li>
    <li>
        Bank, W. (n.d.). <i>World bank open data</i>. Retrieved [05 20, 2024], from 
        <a href="https://data.worldbank.org/" target="_blank">https://data.worldbank.org/</a>.
    </li>
    <li>
        Bell, C. and Badanjak, S. (2019). <i>Introducing pa-x: A new peace agreement database and dataset</i>. 
        <a href="https://journals.sagepub.com/doi/abs/10.1177/0022343318819123?journalCode=jpra" target="_blank">Journal of Peace Research, 56(3):452–466</a>.
    </li>
    <li>
        Bishop, C. M. (2006). <i>Pattern Recognition and Machine Learning</i>. Information Science and Statistics. Springer New York, NY, 1st edition.
    </li>
    <li>
        Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W., and Robins, J. (2018). <i>Double/debiased machine learning for treatment and structural parameters</i>. 
        <a href="https://arxiv.org/abs/1608.00060" target="_blank">The Econometrics Journal, 21(1):C1–C68</a>.
    </li>
    <li>
        Frey, E. and Seimon, B. (2024). <i>PanelSplit: a tool for panel data analysis</i>.
        <a href="https://github.com/4Freye/panelsplit"  target="_blank">
    </li>
    <li>
        Fuhr, J., Berens, P., and Papies, D. (2024). <i>Estimating causal effects with double machine learning–a method evaluation</i>. 
        <a href="https://arxiv.org/abs/2403.14385" target="_blank">arXiv preprint arXiv:2403.14385</a>.
    </li>
    <li>
        Haavelmo, T. (1943). <i>The statistical implications of a system of simultaneous equations</i>. Econometrica, Journal of the Econometric Society, pages 1–12.
    </li>
    <li>
        Malani, A. and Reif, J. (2015). <i>Interpreting pre-trends as anticipation: Impact on estimated treatment effects from tort reform</i>. 
        <a href="https://www.sciencedirect.com/science/article/abs/pii/S0047272715000122" target="_blank">Journal of Public Economics, 124:1–17</a>.
    </li>
    <li>
        Mueller, H. and Rauh, C. (2022). <i>The hard problem of prediction for conflict prevention</i>. 
        <a href="https://academic.oup.com/jeea/article/20/6/2440/6574413" target="_blank">Journal of the European Economic Association, 20(6):2440–2467</a>.
    </li>
    <li>
        Mueller, H. and Rauh, C. (2024). <i>Building bridges to peace: A quantitative evaluation of power-sharing agreements</i>. Economic Policy, page eiae010.
                <a href="https://bse.eu/research/working-papers/building-bridges-peace-quantitative-evaluation-power-sharing-agreements" target="_blank">Data & Policy, 6:e17</a>.
    </li>
    <li>
        Mueller, H., Rauh, C., and Seimon, B. (2024). <i>Introducing a global dataset on conflict forecasts and news topics</i>. 
        <a href="https://www.cambridge.org/core/journals/data-and-policy/article/introducing-a-global-dataset-on-conflict-forecasts-and-news-topics/AADA08BD5FC80EDD01E5CEBA7434F6E0" target="_blank">Data & Policy, 6:e17</a>.
    </li>
    <li>
        Pearl, J. (2000). <i>Causal inference without counterfactuals: Comment</i>. 
        <a href="https://www.tandfonline.com/doi/abs/10.1080/01621459.2000.10474265" target="_blank">Journal of the American Statistical Association, 95(450):428–431</a>.
    </li>
    <li>
        Polselli, A. and Clarke, P. (2023). <i>Double machine learning for static panel models with fixed effects</i>. 
        <a href="https://arxiv.org/abs/2312.08174" target="_blank">arXiv preprint arXiv:2312.08174</a>.
    </li>
    <li>
        Program, U. C. D. (2023). <i>UCDP georeferenced event dataset (GED) codebook</i>. Accessed: 2024-06-02.
    </li>
    <li>
        Robinson, P. M. (1988). <i>Root-n-consistent semiparametric regression</i>. Econometrica: Journal of the Econometric Society, pages 931–954.
    </li>
    <li>
        Stock, J. H., Watson, M. W., and Wooldridge, J. M. (2012). <i>Introductory Econometrics: A Modern Approach</i>. Prentice Hall.
    </li>
    <li>
        Wold, H. (1954). <i>Causality and econometrics</i>. Econometrica: Journal of the Econometric Society, pages 162–177.
    </li>
</ol>
</body>

<!-- title: Mapping Buildings from the Sky with a U-Net Neural Network -->
<!-- featured_image: https://raw.githubusercontent.com/amberwalker-ds/amberwalker-ds.github.io/master/assets/images/unet-feature-image.jpeg-->
<!-- categories: computer_vision -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<figure>
    <img src="https://raw.githubusercontent.com/amberwalker-ds/amberwalker-ds.github.io/master/assets/images/unet-feature-image.jpeg" 
    alt="u-net deep learning model" width="1000" height="700">
</figure>
<body>
    <p>
        This project is all about teaching a neural network to spot buildings from aerial images, and it was honestly one of the most exciting challenges I’ve tackled! 
        Using a U-Net architecture (a powerful model designed for image segmentation), I trained the network to differentiate between buildings and everything else—like trees, roads, and backgrounds.
    </p>
    <p>
        By combining clever techniques like spatial dropout, a custom loss function (Binary Cross-Entropy + Dice Loss), and a bit of patience, I achieved a 94.7% accuracy and a 76.7% Dice score. 
        This means the model does a solid job of identifying and mapping building footprints, even when dealing with the tricky imbalance of having way more background pixels than buildings.
    </p>
    <p>
        For a more detailed look at the project, 
        check out my <b><a href="https://medium.com/ai-advances/how-i-used-a-u-net-to-map-building-footprints-from-the-sky-bf6d184c41d8" class="modern-link">Medium article! &#x1F680;</a></b> 
        Check out my GitHub repo for the full code and feel free to explore how I put it all together. If you're curious about aerial image segmentation, this is a great place to start!
        <a href="https://github.com/amberwalker-ds/u-net_semantic_segmentation" target="_blank">
            <img src="https://img.shields.io/badge/GitHub-View%20Project-blue?logo=github" alt="View on GitHub">
        </a>
    </p>
    <div class="comparison-container">
        <p>Check out the slider below to compare an original image to a predicted image by the model.</p>
        <div class="comparison-slider">
            <div class="comparison-image">
                <img src="https://raw.githubusercontent.com/amberwalker-ds/amberwalker-ds.github.io/master/assets/images/original-image.jpeg" alt="Original Image">
            </div>
            <div class="comparison-image-overlay">
                <img src="https://raw.githubusercontent.com/amberwalker-ds/amberwalker-ds.github.io/master/assets/images/predicted-label.jpeg" alt="Predicted Image">
            </div>
        </div>
        <!-- Slider placed directly below the images -->
        <div class="slider-container">
            <input type="range" min="0" max="100" value="50" id="slider">
        </div>
    </div>
    <script>
        document.addEventListener("DOMContentLoaded", () => {
            const slider = document.getElementById("slider");
            const overlay = document.querySelector(".comparison-image-overlay");
            slider.addEventListener("input", (e) => {
                const value = e.target.value;
                overlay.style.width = `${value}%`;
            });
        });
    </script>
</body>
</html>
